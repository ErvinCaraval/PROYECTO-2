# Soluci√≥n para Container Reinici√°ndose (Restart Count: 5)

## üî¥ Problema Identificado

Tu container en Azure tiene **Restart count: 5**, lo que significa que se ha reiniciado 5 veces. Esto explica los errores `ECONNRESET` - el container se est√° crasheando durante el procesamiento.

## üîç Diagn√≥stico

### Ver Logs del Container

Ejecuta este comando para ver qu√© est√° causando los crashes:

```bash
cd facial-service
./check-azure-logs.sh [TU_RESOURCE_GROUP]
```

O manualmente:

```bash
# Ver logs completos
az container logs \
  --resource-group <TU_RESOURCE_GROUP> \
  --name facial-service-ervin \
  --tail 100

# Ver eventos (muestra por qu√© se reinici√≥)
az container show \
  --resource-group <TU_RESOURCE_GROUP> \
  --name facial-service-ervin \
  --query "containers[0].instanceView.events" \
  --output table
```

## üõ†Ô∏è Causas Comunes y Soluciones

### Causa 1: Memoria Insuficiente (M√ÅS PROBABLE)

DeepFace requiere mucha memoria. Si el container se queda sin memoria, Azure lo mata.

**Soluci√≥n**: Aumentar memoria a m√≠nimo 8GB (recomendado 16GB)

```bash
az container delete --resource-group <TU_RG> --name facial-service-ervin --yes

az container create \
  --resource-group <TU_RG> \
  --name facial-service-ervin \
  --image ervincaravaliibarra/facial-service:latest \
  --dns-name-label facial-service-ervin \
  --ports 5001 \
  --cpu 4 \
  --memory 16 \
  --restart-policy Always
```

### Causa 2: Error en el C√≥digo

El container puede estar crasheando por un error en Python.

**Soluci√≥n**: Verificar logs para ver el error espec√≠fico

```bash
az container logs \
  --resource-group <TU_RG> \
  --name facial-service-ervin \
  --tail 100
```

Busca errores como:
- `MemoryError`
- `Killed` (OOM - Out of Memory)
- `ModuleNotFoundError`
- `ImportError`

### Causa 3: Health Check Falla

Si el health check falla repetidamente, Azure reinicia el container.

**Soluci√≥n**: Verificar que el health endpoint funcione

```bash
curl http://facial-service-ervin.guayfkfebtc3fnda.brazilsouth.azurecontainer.io:5001/health
```

### Causa 4: Timeout en el Procesamiento

Si DeepFace tarda demasiado, Azure puede matar el proceso.

**Soluci√≥n**: Ya implementado (timeout aumentado), pero verifica que el servicio tenga los cambios.

## ‚úÖ Pasos Inmediatos

### 1. Ver Logs
```bash
az container logs \
  --resource-group <TU_RG> \
  --name facial-service-ervin \
  --tail 100
```

### 2. Verificar Recursos Actuales
```bash
az container show \
  --resource-group <TU_RG> \
  --name facial-service-ervin \
  --query "{cpu:containers[0].resources.requests.cpu,memory:containers[0].resources.requests.memoryInGb}"
```

### 3. Aumentar Recursos (Recomendado)

**M√≠nimo recomendado para DeepFace**:
- CPU: 4 cores
- Memory: 16GB

```bash
# Eliminar container actual
az container delete \
  --resource-group <TU_RG> \
  --name facial-service-ervin \
  --yes

# Crear con m√°s recursos
az container create \
  --resource-group <TU_RG> \
  --name facial-service-ervin \
  --image ervincaravaliibarra/facial-service:latest \
  --dns-name-label facial-service-ervin \
  --ports 5001 \
  --cpu 4 \
  --memory 16 \
  --restart-policy Always \
  --registry-login-server docker.io
```

### 4. Verificar que la Imagen Tiene los Cambios

Aseg√∫rate de que la imagen en Docker Hub tenga los cambios del `api.py`:

```bash
cd facial-service
# Reconstruir
docker build -t ervincaravaliibarra/facial-service:latest .

# Subir
docker push ervincaravaliibarra/facial-service:latest

# Actualizar en Azure (usar el script o manualmente)
```

## üìä Monitoreo

Despu√©s de aumentar recursos, monitorea:

```bash
# Ver estado cada 30 segundos
watch -n 30 'az container show --resource-group <TU_RG> --name facial-service-ervin --query "containers[0].instanceView.restartCount" -o tsv'
```

Si el restart count sigue aumentando, hay un problema m√°s profundo que necesita investigaci√≥n.

## üéØ Recomendaci√≥n

**Acci√≥n inmediata**:
1. Ver logs para identificar el error espec√≠fico
2. Aumentar memoria a 16GB (muy probable que sea el problema)
3. Verificar que la imagen tenga los cambios del `api.py`
4. Monitorear el restart count despu√©s de los cambios

Si despu√©s de aumentar a 16GB el problema persiste, considera migrar a **Azure App Service** que tiene mejor manejo de recursos y no mata procesos tan agresivamente.

