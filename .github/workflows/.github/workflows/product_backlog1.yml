name: üöÄ Crear Backlog y Sprints del Proyecto - Visi√≥n Computacional

on:
  workflow_dispatch: # Permite ejecutar este workflow manualmente desde la pesta√±a Actions

# Define el token con permisos de escritura
permissions:
  contents: write # ‚ö†Ô∏è Se cambi√≥ a 'write' para poder crear ramas
  issues: write
  # Es necesario a√±adir permisos para 'pull-requests: write' para que pueda crear etiquetas
  pull-requests: write

jobs:
  setup-project-backlog:
    runs-on: ubuntu-latest
    steps:
      # PASO 1: Descarga el c√≥digo del repositorio
      - name: Checkout repository
        uses: actions/checkout@v4

      # PASO 2 (MODIFICADO): Crea el proyecto si no existe y obtiene su n√∫mero autom√°ticamente
      - name: Crear Proyecto de GitHub si no existe
        id: project_setup # Le damos un ID a este paso para usar sus resultados
        env:
          # ‚ö†Ô∏è MODIFICACI√ìN A√ëADIDA: Usa el Token de Acceso Personal para tener permisos
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          PROJECT_NAME="Product Backlog - Visi√≥n Computacional"
          # ‚ö†Ô∏è MODIFICACI√ìN A√ëADIDA: Comando corregido para buscar el proyecto
          PROJECT_NUMBER=$(gh project list --owner "@me" --format json | jq -r ".projects[] | select(.title == \"$PROJECT_NAME\") | .number")
          
          if [ -z "$PROJECT_NUMBER" ]; then
            echo "Proyecto '$PROJECT_NAME' no encontrado. Cre√°ndolo ahora..."
            # Crea el proyecto y extrae su n√∫mero de la URL resultante
            PROJECT_URL=$(gh project create --owner "@me" --title "$PROJECT_NAME")
            PROJECT_NUMBER=$(echo "$PROJECT_URL" | rev | cut -d'/' -f1 | rev)
            echo "Proyecto creado con el n√∫mero: $PROJECT_NUMBER"
          else
            echo "Proyecto '$PROJECT_NAME' ya existe con el n√∫mero: $PROJECT_NUMBER"
          fi
          # Guarda el n√∫mero del proyecto para que otros pasos puedan usarlo
          echo "PROJECT_NUMBER=$PROJECT_NUMBER" >> $GITHUB_OUTPUT

      # PASO 3: Crea las Etiquetas de Prioridad si no existen
      - name: Crear Etiquetas de Prioridad si no existen
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }} # Usamos el PAT para consistencia
        run: |
          echo "Creando etiquetas de prioridad..."
          gh label create "Prioridad: Alta" --color "D93F0B" --description "Esta tarea es cr√≠tica y bloquea otras." || echo "La etiqueta 'Prioridad: Alta' ya existe."
          gh label create "Prioridad: Media" --color "FBCA04" --description "Tarea importante pero no urgente." || echo "La etiqueta 'Prioridad: Media' ya existe."
          gh label create "Prioridad: Baja" --color "0E8A16" --description "Tarea menor o mejora deseable." || echo "La etiqueta 'Prioridad: Baja' ya existe."
          
          echo "Creando etiquetas de tipo..."
          gh label create "Backend" --color "1D76DB" --description "Tareas de backend y APIs." || echo "La etiqueta 'Backend' ya existe."
          gh label create "Frontend" --color "5319E7" --description "Tareas de frontend y UI." || echo "La etiqueta 'Frontend' ya existe."
          gh label create "IA/ML" --color "FF6B6B" --description "Tareas relacionadas con Inteligencia Artificial." || echo "La etiqueta 'IA/ML' ya existe."
      
      # PASO 4: Crea los Milestones (Sprints) solo si no existen
      - name: Crear Milestones si no existen
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }} # Usamos el PAT para consistencia
          GH_REPO: ${{ github.repository }}
        run: |
          # --- Sprint Semana 1: 17-19 Noviembre ---
          MILESTONE_W1_TITLE="Sprint Visi√≥n Computacional - Semana 1 (17-19 Nov 2025)"
          if gh api /repos/${GH_REPO}/milestones --paginate -q ".[] | select(.title == \"$MILESTONE_W1_TITLE\")" | grep -qF "$MILESTONE_W1_TITLE"; then
            echo "Milestone '$MILESTONE_W1_TITLE' ya existe. Omitiendo."
          else
            echo "Creando milestone '$MILESTONE_W1_TITLE'..."
            gh api --method POST -H "Accept: application/vnd.github+json" "/repos/${GH_REPO}/milestones" \
              -f title="$MILESTONE_W1_TITLE" \
              -f description='Implementaci√≥n de funcionalidades de visi√≥n computacional con Azure. Semana 1: OCR y Reconocimiento Facial.' \
              -f due_on='2025-11-19T23:59:59Z'
          fi

          # --- Sprint Semana 2: 20-24 Noviembre ---
          MILESTONE_W2_TITLE="Sprint Visi√≥n Computacional - Semana 2 (20-24 Nov 2025)"
          if gh api /repos/${GH_REPO}/milestones --paginate -q ".[] | select(.title == \"$MILESTONE_W2_TITLE\")" | grep -qF "$MILESTONE_W2_TITLE"; then
            echo "Milestone '$MILESTONE_W2_TITLE' ya existe. Omitiendo."
          else
            echo "Creando milestone '$MILESTONE_W2_TITLE'..."
            gh api --method POST -H "Accept: application/vnd.github+json" "/repos/${GH_REPO}/milestones" \
              -f title="$MILESTONE_W2_TITLE" \
              -f description='Implementaci√≥n de funcionalidades de visi√≥n computacional con Azure. Semana 2: An√°lisis de Im√°genes y Detecci√≥n de Objetos.' \
              -f due_on='2025-11-24T23:59:59Z'
          fi

      # PASO 5: Crea todos los Issues, los a√±ade al proyecto y solo si no existen
      - name: Crear Issues y a√±adirlas al Proyecto
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }} # Usamos el PAT para consistencia
          PROJECT_NUMBER: ${{ steps.project_setup.outputs.PROJECT_NUMBER }}
        run: |
          # La funci√≥n ahora tambi√©n a√±ade la issue al proyecto.
          create_and_add_to_project() {
            local title="$1"
            local body="$2"
            local labels="$3"
            local milestone="$4"
            
            ISSUE_URL=$(gh issue list --state all --search "in:title \"$title\"" --json url -q ".[0].url")

            if [ -n "$ISSUE_URL" ]; then
              echo "Issue '$title' ya existe. Omitiendo creaci√≥n."
            else
              echo "Creando issue '$title'..."
              # Separar etiquetas por comas
              IFS=',' read -ra LABEL_ARRAY <<< "$labels"
              LABEL_ARGS=""
              for label in "${LABEL_ARRAY[@]}"; do
                LABEL_ARGS="$LABEL_ARGS --label \"$label\""
              done
              
              ISSUE_URL=$(eval "gh issue create --title \"$title\" --body \"$body\" $LABEL_ARGS --milestone \"$milestone\"")
            fi

            if [ -n "$ISSUE_URL" ]; then
                echo "A√±adiendo issue $ISSUE_URL al proyecto ${{ env.PROJECT_NUMBER }}..."
                PROJECT_ID=$(gh project view ${{ env.PROJECT_NUMBER }} --owner "@me" --format json | jq -r '.id')
                CONTENT_ID=$(gh issue view $ISSUE_URL --json id | jq -r '.id')

                # A√±ade la issue al proyecto y obtiene el ID del item
                ITEM_ID=$(gh api graphql -f query='
                  mutation($project:ID!, $content:ID!) {
                    addProjectV2ItemById(input: {projectId: $project, contentId: $content}) {
                      item { id }
                    }
                  }
                ' -f project="$PROJECT_ID" -f content="$CONTENT_ID" | jq -r '.data.addProjectV2ItemById.item.id')

                # === MOVER LA ISSUE A LA COLUMNA 'Todo' ===
                TODO_COLUMN_ID="f75ad846"
                STATUS_FIELD_ID="PVTSSF_lAHOCfyr_s4BFLg_zg2l7HM"
                # Actualiza el campo Status del item usando una query m√°s simple
                echo "Moviendo issue a Todo con IDs: PROJECT=$PROJECT_ID, ITEM=$ITEM_ID, FIELD=$STATUS_FIELD_ID, OPTION=$TODO_COLUMN_ID"
                
                # Usar una query GraphQL m√°s simple sin variables complejas
                gh api graphql -f query="
                  mutation {
                    updateProjectV2ItemFieldValue(input: {
                      projectId: \"$PROJECT_ID\",
                      itemId: \"$ITEM_ID\",
                      fieldId: \"$STATUS_FIELD_ID\",
                      value: {singleSelectOptionId: \"$TODO_COLUMN_ID\"}
                    }) {
                      projectV2Item { id }
                    }
                  }
                " || echo "No se pudo mover la issue a la columna 'Todo'. Revisa el ID."
            fi
          }

          # ===============================================
          # ==  HU: VISI√ìN COMPUTACIONAL (AZURE)         ==
          # ==  Organizadas por Estimaci√≥n y Prioridad  ==
          # ==  Fechas: 17-24 Noviembre 2025            ==
          # ===============================================

          # HU 2: Reconocimiento Facial (13 SP, Alta) - Martes 18 Nov
          create_and_add_to_project \
            "[BE] HU-VC1: Reconocimiento Facial para Login y Registro" \
            "## üéØ Historia de Usuario

**Como** usuario de BrainBlitz  
**Quiero** autenticarme usando reconocimiento facial  
**Para que** pueda acceder de forma segura y r√°pida sin depender de contrase√±as

---

## üìã Contexto (C)

Los usuarios de BrainBlitz necesitan una forma segura y moderna de autenticarse sin depender √∫nicamente de contrase√±as. El sistema actual permite registro e inicio de sesi√≥n con email/contrase√±a, pero se requiere implementar autenticaci√≥n biom√©trica mediante reconocimiento facial.

---

## üéØ Objetivo (O)

Permitir que los usuarios se registren e inicien sesi√≥n usando reconocimiento facial como m√©todo de autenticaci√≥n alternativo o principal, mejorando la seguridad y la experiencia de usuario.

---

## üí° Necesidad (N)

Proporcionar una opci√≥n de autenticaci√≥n sin contrase√±a que sea r√°pida, segura y accesible desde dispositivos con c√°mara, reduciendo la fricci√≥n en el proceso de login y mejorando la seguridad mediante biometr√≠a.

---

## üèóÔ∏è Entidades (E)

- Sistema de autenticaci√≥n facial
- Base de datos de usuarios
- Servicio de reconocimiento facial (DeepFace)
- Frontend con acceso a c√°mara
- Backend con endpoints de registro y login facial

---

## üõ†Ô∏è Soporte (S)

- **Microservicio:** \`facial-service\` usando DeepFace
- **Endpoints Backend:** 
  - \`POST /api/face/register\`
  - \`POST /api/face/login\`
- **Frontend:** 
  - \`FaceRegister.jsx\`
  - \`FaceLogin.jsx\`
- **Base de Datos:** Firebase Firestore (embeddings faciales)
- **Despliegue:** Azure Container Instances

---

## üìù Suposiciones (S)

- Los usuarios tienen acceso a dispositivos con c√°mara web
- El navegador soporta acceso a la c√°mara (getUserMedia API)
- El servicio de reconocimiento facial est√° desplegado y accesible
- Los usuarios est√°n dispuestos a registrar su rostro para autenticaci√≥n

---

## ‚úÖ Criterios de Aceptaci√≥n (A)

### 1. Registro Facial
- ‚úÖ Endpoint \`POST /api/face/register\` que acepta imagen Base64 y token Firebase
- ‚úÖ Validaci√≥n de rostro visible usando DeepFace
- ‚úÖ Generaci√≥n de embeddings faciales con modelo VGG-Face
- ‚úÖ Almacenamiento de embeddings en Firestore asociados al userId
- ‚úÖ Prevenci√≥n de duplicados (un usuario = un registro facial)
- ‚úÖ Respuesta exitosa: \`{ success: true, message: 'Cara registrada exitosamente' }\`
- ‚úÖ Manejo de errores: rostro no detectado, token inv√°lido, usuario ya registrado

### 2. Login Facial
- ‚úÖ Endpoint \`POST /api/face/login\` que acepta imagen Base64 y email
- ‚úÖ B√∫squeda de usuario por email en Firebase Auth
- ‚úÖ Verificaci√≥n de registro facial previo
- ‚úÖ Comparaci√≥n facial con embedding almacenado
- ‚úÖ Umbral de confianza m√≠nimo (ej: 0.7)
- ‚úÖ Generaci√≥n de token personalizado de Firebase si verificaci√≥n exitosa
- ‚úÖ Respuesta: \`{ success: true, verified: true, customToken, userId, confidence }\`
- ‚úÖ Manejo de errores: rostro no detectado, usuario no encontrado, verificaci√≥n fallida

### 3. Frontend - Registro Facial
- ‚úÖ Componente \`FaceRegister.jsx\` con vista previa de c√°mara en tiempo real
- ‚úÖ Captura de foto del rostro y conversi√≥n a Base64
- ‚úÖ Env√≠o al endpoint \`/api/face/register\`
- ‚úÖ Mensajes de √©xito/error
- ‚úÖ Solicitud de permisos de c√°mara con \`navigator.mediaDevices.getUserMedia()\`
- ‚úÖ Indicador visual cuando se detecta un rostro
- ‚úÖ Manejo de errores: sin c√°mara, permisos denegados, registro fallido

### 4. Frontend - Login Facial
- ‚úÖ Componente \`FaceLogin.jsx\` con campo de email del usuario
- ‚úÖ Vista previa de c√°mara y captura de foto
- ‚úÖ Env√≠o al endpoint \`/api/face/login\`
- ‚úÖ Autenticaci√≥n con token recibido
- ‚úÖ Integraci√≥n con \`AuthContext\`
- ‚úÖ Redirecci√≥n a p√°gina principal despu√©s de login exitoso

### 5. Seguridad
- ‚úÖ Registro facial requiere token Firebase v√°lido
- ‚úÖ Verificaci√≥n de token antes de procesar registro
- ‚úÖ Almacenamiento seguro de embeddings en Firestore
- ‚úÖ Rate limiting en endpoints para prevenir ataques

### 6. Despliegue
- ‚úÖ Microservicio facial desplegado en Azure Container Instances
- ‚úÖ URL configurada en \`.env\` como \`DEEPFACE_SERVICE_URL\`
- ‚úÖ Health check: \`GET /health\` responde correctamente

### 7. Pruebas
- ‚úÖ Pruebas unitarias para controladores de registro y login
- ‚úÖ Pruebas de integraci√≥n de flujos completos
- ‚úÖ Pruebas manuales en Chrome, Firefox y Edge

---

## üìä Puntos de Estimaci√≥n: **13 Story Points**
## üéØ Prioridad: **Alta**
## üìÖ Fecha Objetivo: **Martes 18 Noviembre 2025**
## üîß Tecnolog√≠as: DeepFace, VGG-Face, Azure Container Instances, Firebase Auth, React" \
            "Prioridad: Alta,Backend,IA/ML" \
            "Sprint Visi√≥n Computacional - Semana 1 (17-19 Nov 2025)"

          # HU 1: OCR - Extracci√≥n de Texto (8 SP, Media) - Lunes 17 Nov
          create_and_add_to_project \
            "[BE] HU-VC2: OCR - Extracci√≥n de Texto de Im√°genes" \
            "## üéØ Historia de Usuario

**Como** administrador o usuario de BrainBlitz  
**Quiero** extraer texto de im√°genes autom√°ticamente  
**Para que** pueda crear preguntas r√°pidamente desde capturas de pantalla o documentos

---

## üìã Contexto (C)

Los usuarios y administradores de BrainBlitz necesitan una forma de convertir im√°genes con texto (pantallas, documentos, carteles, capturas) en texto editable para generar preguntas autom√°ticamente o procesar contenido visual. Actualmente, el sistema requiere que las preguntas se ingresen manualmente, lo cual es lento y propenso a errores.

---

## üéØ Objetivo (O)

Implementar un sistema de reconocimiento √≥ptico de caracteres (OCR) que permita extraer texto de im√°genes subidas por usuarios o administradores, facilitando la creaci√≥n de preguntas y el procesamiento de contenido visual.

---

## üí° Necesidad (N)

Automatizar la extracci√≥n de texto de im√°genes para reducir el tiempo de creaci√≥n de preguntas, permitir que usuarios suban im√°genes con preguntas y convertirlas autom√°ticamente, y mejorar la accesibilidad del contenido visual.

---

## üèóÔ∏è Entidades (E)

- Servicio de OCR (Azure Computer Vision)
- Endpoint backend para procesamiento de im√°genes
- Frontend para subir im√°genes
- Base de datos para almacenar texto extra√≠do
- Sistema de validaci√≥n y limpieza de texto

---

## üõ†Ô∏è Soporte (S)

- **Servicio:** Azure Computer Vision API con OCR
- **Endpoint Backend:** \`POST /api/vision/extract-text\`
- **Frontend:** Componente para subir im√°genes y mostrar texto extra√≠do
- **Variables de Entorno:** 
  - \`AZURE_COMPUTER_VISION_KEY\`
  - \`AZURE_COMPUTER_VISION_ENDPOINT\`
- **Biblioteca:** \`@azure/cognitiveservices-computervision\` o HTTP REST

---

## üìù Suposiciones (S)

- Azure Computer Vision est√° configurado y tiene cr√©ditos disponibles
- Las im√°genes subidas contienen texto legible
- Los usuarios tienen permisos para subir im√°genes
- El texto extra√≠do puede requerir limpieza y validaci√≥n

---

## ‚úÖ Criterios de Aceptaci√≥n (A)

### 1. Configuraci√≥n de Azure
- ‚úÖ Cuenta Azure con Computer Vision habilitado
- ‚úÖ API Key de Azure Computer Vision disponible
- ‚úÖ URL del endpoint de Azure Computer Vision
- ‚úÖ Variables \`AZURE_COMPUTER_VISION_KEY\` y \`AZURE_COMPUTER_VISION_ENDPOINT\` en \`.env\`
- ‚úÖ Instalaci√≥n de \`@azure/cognitiveservices-computervision\` o uso de \`axios\`/\`fetch\`

### 2. Endpoint Backend
- ‚úÖ Ruta \`POST /api/vision/extract-text\` en \`backend-v1/routes/vision.routes.js\`
- ‚úÖ Controlador \`visionController.js\` con m√©todo \`extractText\`
- ‚úÖ Middleware de autenticaci√≥n \`authenticate.js\`
- ‚úÖ Validaci√≥n de imagen en Base64 o archivo
- ‚úÖ L√≠mite de tama√±o de 4MB (l√≠mite de Azure)

### 3. Integraci√≥n con Azure OCR
- ‚úÖ Conversi√≥n de Base64 a buffer binario
- ‚úÖ POST a \`https://{endpoint}/vision/v3.2/read/analyze\`
- ‚úÖ Headers: \`Ocp-Apim-Subscription-Key\` y \`Content-Type: application/octet-stream\`
- ‚úÖ Manejo de procesamiento as√≠ncrono de Azure (analyze ‚Üí get results)
- ‚úÖ Extracci√≥n de todas las l√≠neas de texto de la respuesta
- ‚úÖ Formato de respuesta limpio y estructurado

### 4. Respuesta del Endpoint
- ‚úÖ Formato JSON: \`{ success: true, text: string, language: string, confidence: number, lines: array }\`
- ‚úÖ Texto completo concatenado
- ‚úÖ Array con cada l√≠nea de texto detectada
- ‚úÖ Idioma detectado (es, en, etc.)
- ‚úÖ Nivel de confianza promedio

### 5. Manejo de Errores
- ‚úÖ Error 400 si imagen inv√°lida
- ‚úÖ Mensaje claro si no se detecta texto
- ‚úÖ Manejo de errores de Azure (401, 429, 500)
- ‚úÖ Manejo de timeouts con reintentos
- ‚úÖ Logging de errores para debugging

### 6. Pruebas
- ‚úÖ Prueba unitaria de funci√≥n de extracci√≥n
- ‚úÖ Prueba de integraci√≥n del endpoint completo
- ‚úÖ Prueba de manejo de errores
- ‚úÖ Prueba manual con JPG, PNG, PDF

### 7. Integraci√≥n con el Juego - Frontend
- ‚úÖ Componente \`OCRQuestionCreator.jsx\` con subida de imagen (drag & drop o bot√≥n)
- ‚úÖ Preview de imagen subida
- ‚úÖ Bot√≥n \"Extraer Texto\" ‚Üí llamada a \`/api/vision/extract-text\`
- ‚úÖ Spinner de carga mientras procesa
- ‚úÖ Textarea editable con texto extra√≠do
- ‚úÖ Bot√≥n \"Usar como Pregunta\" ‚Üí pre-llena formulario
- ‚úÖ Integraci√≥n con \`AIQuestionGenerator.jsx\`
- ‚úÖ Flujo completo de creaci√≥n de preguntas desde OCR
- ‚úÖ Preguntas creadas desde OCR aparecen en juegos normalmente

### 8. Documentaci√≥n
- ‚úÖ Endpoint documentado en \`swagger.yaml\`
- ‚úÖ Instrucciones de configuraci√≥n de Azure en README
- ‚úÖ Ejemplos de uso del endpoint

---

## üìä Puntos de Estimaci√≥n: **8 Story Points**
## üéØ Prioridad: **Media**
## üìÖ Fecha Objetivo: **Lunes 17 Noviembre 2025**
## üîß Tecnolog√≠as: Azure Computer Vision OCR, Node.js, Express, React" \
            "Prioridad: Media,Backend,IA/ML" \
            "Sprint Visi√≥n Computacional - Semana 1 (17-19 Nov 2025)"

          # HU 3: An√°lisis de Im√°genes (10 SP, Media) - Jueves 20 Nov
          create_and_add_to_project \
            "[BE] HU-VC3: An√°lisis Inteligente de Im√°genes" \
            "## üéØ Historia de Usuario

**Como** creador de contenido en BrainBlitz  
**Quiero** analizar im√°genes autom√°ticamente para obtener descripciones y tags  
**Para que** pueda generar preguntas visuales de forma r√°pida y autom√°tica

---

## üìã Contexto (C)

Los usuarios y administradores de BrainBlitz necesitan generar preguntas autom√°ticamente a partir de im√°genes. Actualmente, las preguntas se crean manualmente o mediante IA basada en texto. Se requiere un sistema que analice im√°genes y genere descripciones, tags y categor√≠as autom√°ticamente para facilitar la creaci√≥n de preguntas visuales.

---

## üéØ Objetivo (O)

Implementar un sistema de an√°lisis inteligente de im√°genes que genere descripciones autom√°ticas, tags, categor√≠as y metadatos de im√°genes, permitiendo crear preguntas de trivia basadas en contenido visual de forma autom√°tica.

---

## üí° Necesidad (N)

Automatizar la generaci√≥n de contenido para preguntas visuales, mejorar la accesibilidad describiendo im√°genes, y permitir b√∫squeda y categorizaci√≥n autom√°tica de im√°genes por contenido.

---

## üèóÔ∏è Entidades (E)

- Servicio de an√°lisis de im√°genes (Azure Computer Vision)
- Endpoint backend para an√°lisis
- Frontend para subir y visualizar an√°lisis
- Base de datos para almacenar metadatos de im√°genes
- Sistema de generaci√≥n de preguntas basado en an√°lisis

---

## üõ†Ô∏è Soporte (S)

- **Servicio:** Azure Computer Vision API Analyze Image
- **Endpoint Backend:** \`POST /api/vision/analyze-image\`
- **Frontend:** Componente para subir im√°genes y mostrar an√°lisis
- **Variables de Entorno:** 
  - \`AZURE_COMPUTER_VISION_KEY\`
  - \`AZURE_COMPUTER_VISION_ENDPOINT\`
- **Biblioteca:** \`@azure/cognitiveservices-computervision\` o HTTP REST

---

## üìù Suposiciones (S)

- Azure Computer Vision est√° configurado
- Las im√°genes contienen contenido reconocible
- Los usuarios tienen permisos para subir im√°genes
- El an√°lisis puede usarse para generar preguntas autom√°ticamente

---

## ‚úÖ Criterios de Aceptaci√≥n (A)

### 1. Configuraci√≥n de Azure
- ‚úÖ Variable \`AZURE_COMPUTER_VISION_KEY\` en \`.env\`
- ‚úÖ Variable \`AZURE_COMPUTER_VISION_ENDPOINT\` en \`.env\`
- ‚úÖ Dependencias instaladas

### 2. Endpoint Backend
- ‚úÖ Ruta \`POST /api/vision/analyze-image\` en \`backend-v1/routes/vision.routes.js\`
- ‚úÖ M√©todo \`analyzeImage\` en \`visionController.js\`
- ‚úÖ Autenticaci√≥n requerida
- ‚úÖ Validaci√≥n de imagen Base64 o archivo, m√°ximo 4MB

### 3. Integraci√≥n con Azure Analyze Image
- ‚úÖ POST a \`https://{endpoint}/vision/v3.2/analyze?visualFeatures=Description,Tags,Categories,Objects,Color\`
- ‚úÖ Headers: \`Ocp-Apim-Subscription-Key\` y \`Content-Type: application/octet-stream\`
- ‚úÖ Par√°metros visuales: Description, Tags, Categories, Objects, Color
- ‚úÖ Procesamiento correcto de respuesta JSON

### 4. Extracci√≥n de Datos
- ‚úÖ Descripci√≥n principal y descripciones alternativas
- ‚úÖ Tags con niveles de confianza
- ‚úÖ Categor√≠as detectadas (abstract, people, outdoor, etc.)
- ‚úÖ Objetos detectados con bounding boxes
- ‚úÖ Colores dominantes y acento de color
- ‚úÖ Metadatos: dimensiones, formato

### 5. Respuesta del Endpoint
- ‚úÖ Objeto JSON estructurado con descripci√≥n, tags, categor√≠as, objetos y colores
- ‚úÖ Niveles de confianza incluidos
- ‚úÖ Tags y categor√≠as ordenados por confianza descendente

### 6. Manejo de Errores
- ‚úÖ Error 400 con mensaje claro para imagen inv√°lida
- ‚úÖ Mensaje si no se detecta contenido reconocible
- ‚úÖ Manejo de 401, 429, 500 con mensajes apropiados
- ‚úÖ Manejo de timeouts con reintentos
- ‚úÖ Logging de errores

### 7. Pruebas
- ‚úÖ Prueba unitaria con imagen de prueba
- ‚úÖ Prueba de integraci√≥n del endpoint
- ‚úÖ Prueba con im√°genes de arte, geograf√≠a, objetos, personas
- ‚úÖ Verificaci√≥n de manejo de errores

### 8. Integraci√≥n con el Juego - Frontend
- ‚úÖ Componente \`ImageAnalysisQuestionCreator.jsx\` con subida de imagen
- ‚úÖ Bot√≥n \"Analizar Imagen\" ‚Üí llamada a \`/api/vision/analyze-image\`
- ‚úÖ Resultados en secciones: Descripci√≥n, Tags, Categor√≠as, Objetos
- ‚úÖ Generaci√≥n Autom√°tica de Preguntas con bot√≥n \"Generar Pregunta desde An√°lisis\"
- ‚úÖ Pre-llenado de formulario con pregunta sugerida
- ‚úÖ Integraci√≥n con \`AIQuestionGenerator\`
- ‚úÖ Flujo completo de usuario desde subida hasta creaci√≥n de pregunta
- ‚úÖ Preguntas aparecen en juegos con imagen asociada

### 9. Documentaci√≥n
- ‚úÖ Endpoint documentado en Swagger
- ‚úÖ Ejemplos de im√°genes y respuestas esperadas
- ‚úÖ Gu√≠a de integraci√≥n para generar preguntas

---

## üìä Puntos de Estimaci√≥n: **10 Story Points**
## üéØ Prioridad: **Media**
## üìÖ Fecha Objetivo: **Jueves 20 Noviembre 2025**
## üîß Tecnolog√≠as: Azure Computer Vision Analyze Image, Node.js, Express, React" \
            "Prioridad: Media,Backend,IA/ML" \
            "Sprint Visi√≥n Computacional - Semana 2 (20-24 Nov 2025)"

          # HU 4: Detecci√≥n de Objetos (10 SP, Media) - Viernes 21 Nov
          create_and_add_to_project \
            "[BE] HU-VC4: Detecci√≥n de Objetos en Im√°genes" \
            "## üéØ Historia de Usuario

**Como** creador de preguntas visuales  
**Quiero** detectar y localizar objetos en im√°genes autom√°ticamente  
**Para que** pueda crear preguntas interactivas sobre identificaci√≥n y conteo de objetos

---

## üìã Contexto (C)

Los usuarios de BrainBlitz necesitan crear preguntas visuales donde se identifiquen objetos espec√≠ficos en im√°genes. Por ejemplo, \"¬øQu√© objeto aparece en esta imagen?\" o \"¬øCu√°ntos objetos de tipo X hay en la imagen?\". Actualmente, no existe funcionalidad para detectar y localizar objetos en im√°genes.

---

## üéØ Objetivo (O)

Implementar un sistema de detecci√≥n de objetos que identifique y localice objetos espec√≠ficos dentro de im√°genes, permitiendo crear preguntas interactivas basadas en la detecci√≥n de objetos y mejorar la experiencia de preguntas visuales.

---

## üí° Necesidad (N)

Habilitar la creaci√≥n de preguntas visuales interactivas, permitir b√∫squeda de objetos en im√°genes, y mejorar la accesibilidad describiendo qu√© objetos est√°n presentes en una imagen.

---

## üèóÔ∏è Entidades (E)

- Servicio de detecci√≥n de objetos (Azure Computer Vision)
- Endpoint backend para detecci√≥n
- Frontend para visualizar objetos detectados
- Base de datos para almacenar detecciones
- Sistema de preguntas basadas en objetos

---

## üõ†Ô∏è Soporte (S)

- **Servicio:** Azure Computer Vision API Object Detection
- **Endpoint Backend:** \`POST /api/vision/detect-objects\`
- **Frontend:** Componente para mostrar objetos con bounding boxes
- **Variables de Entorno:** 
  - \`AZURE_COMPUTER_VISION_KEY\`
  - \`AZURE_COMPUTER_VISION_ENDPOINT\`
- **Biblioteca:** \`@azure/cognitiveservices-computervision\` o HTTP REST

---

## üìù Suposiciones (S)

- Azure Computer Vision soporta detecci√≥n de objetos
- Las im√°genes contienen objetos reconocibles
- Los usuarios necesitan crear preguntas basadas en objetos detectados

---

## ‚úÖ Criterios de Aceptaci√≥n (A)

### 1. Configuraci√≥n de Azure
- ‚úÖ Variable \`AZURE_COMPUTER_VISION_KEY\` configurada
- ‚úÖ Variable \`AZURE_COMPUTER_VISION_ENDPOINT\` configurada
- ‚úÖ Librer√≠a de Azure instalada o HTTP REST

### 2. Endpoint Backend
- ‚úÖ Ruta \`POST /api/vision/detect-objects\` en \`backend-v1/routes/vision.routes.js\`
- ‚úÖ M√©todo \`detectObjects\` en \`visionController.js\`
- ‚úÖ Autenticaci√≥n requerida
- ‚úÖ Validaci√≥n de imagen Base64 o archivo, m√°ximo 4MB

### 3. Integraci√≥n con Azure Object Detection
- ‚úÖ POST a \`https://{endpoint}/vision/v3.2/detect\`
- ‚úÖ Headers: \`Ocp-Apim-Subscription-Key\` y \`Content-Type: application/octet-stream\`
- ‚úÖ Procesamiento de respuesta JSON con objetos detectados

### 4. Extracci√≥n de Objetos
- ‚úÖ Lista de objetos con nombre, confianza, bounding box y √°rea
- ‚úÖ Filtrado opcional por confianza < 0.5
- ‚úÖ Ordenamiento por confianza descendente o √°rea

### 5. Respuesta del Endpoint
- ‚úÖ Formato JSON con array de objetos, total y dimensiones de imagen
- ‚úÖ Metadatos: total de objetos y dimensiones
- ‚úÖ Bounding boxes en p√≠xeles o normalizados (0-1)

### 6. Funcionalidades Adicionales
- ‚úÖ Par√°metro opcional \`objectName\` para buscar objeto espec√≠fico
- ‚úÖ Conteo de cada tipo de objeto
- ‚úÖ Agrupaci√≥n de objetos del mismo tipo

### 7. Manejo de Errores
- ‚úÖ Error 400 con mensaje claro para imagen inv√°lida
- ‚úÖ Lista vac√≠a si no se detectan objetos (no error)
- ‚úÖ Manejo de errores de API con mensajes apropiados
- ‚úÖ Manejo de timeouts
- ‚úÖ Logging de errores

### 8. Pruebas
- ‚úÖ Prueba unitaria con imagen de prueba
- ‚úÖ Prueba de integraci√≥n del endpoint
- ‚úÖ Verificaci√≥n de detecci√≥n de m√∫ltiples objetos
- ‚úÖ Verificaci√≥n de precisi√≥n
- ‚úÖ Verificaci√≥n de manejo de errores

### 9. Integraci√≥n con el Juego - Frontend
- ‚úÖ Componente \`ObjectDetectionQuestionCreator.jsx\` con:
  - Subida de imagen (drag & drop o bot√≥n)
  - Preview de imagen
  - Bot√≥n \"Detectar Objetos\" ‚Üí llamada a \`/api/vision/detect-objects\`
  - Imagen con bounding boxes dibujados sobre objetos
  - Lista de objetos con nombre, confianza y posici√≥n
- ‚úÖ Visualizaci√≥n Interactiva:
  - Hover sobre objeto ‚Üí resalta bounding box
  - Clic en bounding box ‚Üí resalta en lista
  - Filtro por confianza m√≠nima (slider)
  - Contador por tipo de objeto
- ‚úÖ Generaci√≥n Autom√°tica de Preguntas:
  - Bot√≥n \"Crear Pregunta de Objetos\"
  - Genera preguntas de identificaci√≥n: \"¬øQu√© objeto aparece?\"
  - Genera preguntas de conteo: \"¬øCu√°ntos [objeto] hay?\"
  - Pre-llena formulario con pregunta y opciones
- ‚úÖ Integraci√≥n con \`AIQuestionGenerator\`
- ‚úÖ Flujo completo de usuario
- ‚úÖ Preguntas aparecen en juegos con imagen (sin bounding boxes)
- ‚úÖ Jugadores responden pregunta normalmente

### 10. Documentaci√≥n
- ‚úÖ Endpoint documentado en Swagger
- ‚úÖ Ejemplos visuales de im√°genes y objetos detectados
- ‚úÖ Gu√≠a de uso para crear preguntas

---

## üìä Puntos de Estimaci√≥n: **10 Story Points**
## üéØ Prioridad: **Media**
## üìÖ Fecha Objetivo: **Viernes 21 Noviembre 2025**
## üîß Tecnolog√≠as: Azure Computer Vision Object Detection, Node.js, Express, React, Canvas API" \
            "Prioridad: Media,Backend,IA/ML" \
            "Sprint Visi√≥n Computacional - Semana 2 (20-24 Nov 2025)"
      
      # PASO 6: Crea y Vincula las Ramas para cada Issue
      - name: Crear Ramas y Vincularlas a las Issues
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }} # Usamos el PAT para consistencia
        run: |
          MAIN_BRANCH_SHA=$(git rev-parse main)
          gh issue list --state open --json number,title | jq -c '.[]' | while read issue; do
            ISSUE_NUMBER=$(echo $issue | jq -r '.number')
            ISSUE_TITLE=$(echo $issue | jq -r '.title')
            # Limpiar el t√≠tulo para crear el nombre de la rama
            BRANCH_TITLE=$(echo "$ISSUE_TITLE" | iconv -t ascii//TRANSLIT | sed -E 's/\[(BE|FE)\] //g' | sed -E 's/HU-VC[0-9]+: //g' | sed -E 's/[^a-zA-Z0-9]+/-/g' | sed -E 's/^-+|-+$//g' | tr '[:upper:]' '[:lower:]')
            BRANCH_NAME="feature/hu-vc-${ISSUE_NUMBER}-${BRANCH_TITLE}"

            if git ls-remote --heads origin "$BRANCH_NAME" | grep -q "$BRANCH_NAME"; then
              echo "La rama '$BRANCH_NAME' ya existe."
            else
              echo "Creando rama '$BRANCH_NAME'..."
              gh api repos/${{ github.repository }}/git/refs --method POST -f ref="refs/heads/${BRANCH_NAME}" -f sha="$MAIN_BRANCH_SHA"
              # Comenta en la issue para vincular la rama
              gh issue comment $ISSUE_NUMBER --body "üåø Se ha creado la rama de trabajo para esta Historia de Usuario:

\`\`\`
$BRANCH_NAME
\`\`\`

### üìù Instrucciones para trabajar en esta HU:

1. **Clonar y cambiar a la rama:**
   \`\`\`bash
   git fetch origin
   git checkout $BRANCH_NAME
   \`\`\`

2. **Hacer commits siguiendo conventional commits:**
   \`\`\`bash
   git commit -m \"feat(vision): implement OCR endpoint\"
   git commit -m \"test(vision): add unit tests for face recognition\"
   \`\`\`

3. **Push de cambios:**
   \`\`\`bash
   git push origin $BRANCH_NAME
   \`\`\`

4. **Crear Pull Request cuando est√© listo:**
   - El PR debe apuntar a \`main\`
   - Incluir capturas de pantalla o demos si aplica
   - Marcar esta issue con el n√∫mero del PR

¬°√âxito con el desarrollo! üöÄ"
            fi
          done
